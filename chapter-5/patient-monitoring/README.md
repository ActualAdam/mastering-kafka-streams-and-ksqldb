# Patient Monitoring Application
This code corresponds with Chapter 5 in the upcoming O'Reilly book: [Mastering Kafka Streams and ksqlDB][book] by Mitch Seymour. This tutorial covers **Windows and Time** in Kafka Streams. Here, we demonstrate many time-centric operations in Kafka Streams' high-level DSL (including windowed joins and windowed aggregations) by building a patient monitoring system.

This tutorial was inspired by a use case at Children's Healthcare of Atlanta (CHOA). Special thanks to Ramesh Sringeri for helping me understand the use case at CHOA.

[book]: https://www.kafka-streams-book.com/

# Running Locally
The only dependency for running these examples is [Docker][docker]. Everything else is executed within a sandbox image. To mount and run the code for this tutorial in the sandbox image, simply run the following commands:

[docker]: https://www.docker.com/products/docker-desktop

```bash
# make sure you're in same directory as this README
cd /path/to/chapter-5/patient-monitoring

# mount and run the code
docker run --name ch5-sandbox \
  -v "$(pwd)":/app \
  -w /app \
  -p 7000:7000 \
  -ti magicalpipelines/cp-sandbox:latest  bash -c "\
    confluent local start schema-registry; \
    ./scripts/create-topics.sh; \
    ./gradlew run --info"
```

It may take a couple of minutes to start the first time you run the above command.

# Producing Test Data
Once your application is running, you can produce some test data to see it in action. Since our patient monitoring application reads from multiple topics (`pulse-events`, `body-temp-events`), we have saved example records for each topic in the `data/` directory. To produce data into each of these topics, open a new tab in your shell and run the following commands.


```bash
docker exec -ti ch5-sandbox \
    bash -c "kafka-console-producer \
    --broker-list localhost:9092  \
    --topic pulse-events \
    --property 'parse.key=true' \
    --property 'key.separator=|' < data/pulse-events.json"
```

```bash
docker exec -ti ch5-sandbox \
    bash -c "kafka-console-producer \
    --broker-list localhost:9092  \
    --topic body-temp-events \
    --property 'parse.key=true' \
    --property 'key.separator=|' < data/body-temp-events.json"
```

# Consuming the alerts
This Kafka Streams application writes to an `alerts` topic whenever a patient experiences a combination of symptoms that could indicate an infection (high heart rate and body temperature). After producing the test data, you can view the alerts that were generated by consuming from the `alerts` topic. The following command shows how to do that.

```
docker exec -ti ch5-sandbox \
    bash -c "kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic alerts \
  --from-beginning"
```

You should see an alert similar to the following (prettified for readability):

```json
{
  "heart_rate": 120,
  "body_temp": {
    "timestamp": "2020-11-23T09:03:06.500Z",
    "temperature": 101.2,
    "unit": "F"
  }
}
```


# Query the API
Our patient monitoring application also exposes patient heart rates using Kafka Streams' interactive queries feature. The API is listening on port `7000`. Note the following examples use `jq` to prettify the output. If you don't have `jq` installed, either [install it][jq] or remove that part of the command.

[jq]: https://stedolan.github.io/jq/download/

### Get the heart rate for all patients, grouped by window
```bash
curl localhost:7000/bpm/all
```

You should see some output like the following:
```json
{
  "[1@1606122120000/1606122180000]": 120
}
```

The cryptic looking format is actually a compound key, made up of the patient ID and the timerange that the patient's BPM was calculated over. More specifically, the above output translates to:

```json
{
  "[patient_id@time_start/time_end]": bpm
}
```

You could of course massage the output format a bit, but we'll leave that as an exercise to the reader :)

### Get the heart rate for a single patient, within a specific time range
The following query will execute a windowed range scan under the hood. You can replace `1/1606122180000/1606122240000` with any valid value included in the output of the `curl localhost:7000/bpm/all` query we executed above.

```bash
curl localhost:7000/bpm/range/1/1606122120000/1606122180000
```

You should see output similar to the following:

```json
[
  {
    "count": 120,
    "timestamp": "2020-11-23T09:02:00Z"
  }
]
```
